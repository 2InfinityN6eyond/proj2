{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46338ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WC', 'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic',\n",
      "       'function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they',\n",
      "       'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate',\n",
      "       'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect',\n",
      "       'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend',\n",
      "       'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat',\n",
      "       'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body',\n",
      "       'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achieve',\n",
      "       'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture',\n",
      "       'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home',\n",
      "       'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent',\n",
      "       'nonflu', 'filler', 'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC',\n",
      "       'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP',\n",
      "       'label'],\n",
      "      dtype='object') Index(['WC', 'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic',\n",
      "       'function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they',\n",
      "       'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate',\n",
      "       'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect',\n",
      "       'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend',\n",
      "       'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat',\n",
      "       'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body',\n",
      "       'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achieve',\n",
      "       'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture',\n",
      "       'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home',\n",
      "       'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent',\n",
      "       'nonflu', 'filler', 'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC',\n",
      "       'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor dt in raw_df.dtypes :\\n    print(dt)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"./data/train.csv\"\n",
    "\n",
    "raw_df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "train_df = raw_df.loc[:, raw_df.columns != \"label\"]\n",
    "\n",
    "print(raw_df.columns, train_df.columns)\n",
    "\n",
    "'''\n",
    "for dt in raw_df.dtypes :\n",
    "    print(dt)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "500ee2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>Authentic</th>\n",
       "      <th>Tone</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>function</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>...</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>51.81</td>\n",
       "      <td>51.86</td>\n",
       "      <td>38.80</td>\n",
       "      <td>55.50</td>\n",
       "      <td>25.07</td>\n",
       "      <td>21.80</td>\n",
       "      <td>74.86</td>\n",
       "      <td>43.88</td>\n",
       "      <td>14.66</td>\n",
       "      <td>...</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>19.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>883</td>\n",
       "      <td>12.54</td>\n",
       "      <td>52.27</td>\n",
       "      <td>60.12</td>\n",
       "      <td>88.84</td>\n",
       "      <td>19.20</td>\n",
       "      <td>14.04</td>\n",
       "      <td>92.07</td>\n",
       "      <td>60.82</td>\n",
       "      <td>20.84</td>\n",
       "      <td>...</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>19.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1593</td>\n",
       "      <td>63.46</td>\n",
       "      <td>62.10</td>\n",
       "      <td>37.47</td>\n",
       "      <td>57.83</td>\n",
       "      <td>28.96</td>\n",
       "      <td>14.69</td>\n",
       "      <td>83.18</td>\n",
       "      <td>57.06</td>\n",
       "      <td>17.01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>970</td>\n",
       "      <td>36.80</td>\n",
       "      <td>24.16</td>\n",
       "      <td>72.78</td>\n",
       "      <td>92.82</td>\n",
       "      <td>13.29</td>\n",
       "      <td>14.74</td>\n",
       "      <td>91.75</td>\n",
       "      <td>59.07</td>\n",
       "      <td>19.59</td>\n",
       "      <td>...</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>11.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1339</td>\n",
       "      <td>39.78</td>\n",
       "      <td>47.91</td>\n",
       "      <td>38.15</td>\n",
       "      <td>95.89</td>\n",
       "      <td>28.49</td>\n",
       "      <td>17.63</td>\n",
       "      <td>86.41</td>\n",
       "      <td>52.73</td>\n",
       "      <td>17.48</td>\n",
       "      <td>...</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5.30</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.97</td>\n",
       "      <td>12.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>1459</td>\n",
       "      <td>37.27</td>\n",
       "      <td>13.04</td>\n",
       "      <td>94.70</td>\n",
       "      <td>88.49</td>\n",
       "      <td>44.21</td>\n",
       "      <td>14.05</td>\n",
       "      <td>86.36</td>\n",
       "      <td>54.83</td>\n",
       "      <td>17.96</td>\n",
       "      <td>...</td>\n",
       "      <td>3.91</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.26</td>\n",
       "      <td>11.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>1654</td>\n",
       "      <td>22.17</td>\n",
       "      <td>16.36</td>\n",
       "      <td>87.19</td>\n",
       "      <td>64.73</td>\n",
       "      <td>23.63</td>\n",
       "      <td>14.51</td>\n",
       "      <td>90.57</td>\n",
       "      <td>61.91</td>\n",
       "      <td>20.19</td>\n",
       "      <td>...</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0.12</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>1673</td>\n",
       "      <td>42.46</td>\n",
       "      <td>30.78</td>\n",
       "      <td>85.61</td>\n",
       "      <td>76.57</td>\n",
       "      <td>15.35</td>\n",
       "      <td>17.27</td>\n",
       "      <td>87.99</td>\n",
       "      <td>57.14</td>\n",
       "      <td>19.13</td>\n",
       "      <td>...</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>9.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>1433</td>\n",
       "      <td>25.87</td>\n",
       "      <td>55.54</td>\n",
       "      <td>30.88</td>\n",
       "      <td>95.40</td>\n",
       "      <td>11.65</td>\n",
       "      <td>15.00</td>\n",
       "      <td>88.35</td>\n",
       "      <td>55.97</td>\n",
       "      <td>17.10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.98</td>\n",
       "      <td>11.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>1495</td>\n",
       "      <td>39.29</td>\n",
       "      <td>16.94</td>\n",
       "      <td>85.79</td>\n",
       "      <td>69.88</td>\n",
       "      <td>93.44</td>\n",
       "      <td>13.71</td>\n",
       "      <td>91.04</td>\n",
       "      <td>58.60</td>\n",
       "      <td>16.66</td>\n",
       "      <td>...</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.74</td>\n",
       "      <td>10.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6940 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        WC  Analytic  Clout  Authentic   Tone    WPS  Sixltr    Dic  function   \n",
       "0     1078     51.81  51.86      38.80  55.50  25.07   21.80  74.86     43.88  \\\n",
       "1      883     12.54  52.27      60.12  88.84  19.20   14.04  92.07     60.82   \n",
       "2     1593     63.46  62.10      37.47  57.83  28.96   14.69  83.18     57.06   \n",
       "3      970     36.80  24.16      72.78  92.82  13.29   14.74  91.75     59.07   \n",
       "4     1339     39.78  47.91      38.15  95.89  28.49   17.63  86.41     52.73   \n",
       "...    ...       ...    ...        ...    ...    ...     ...    ...       ...   \n",
       "6935  1459     37.27  13.04      94.70  88.49  44.21   14.05  86.36     54.83   \n",
       "6936  1654     22.17  16.36      87.19  64.73  23.63   14.51  90.57     61.91   \n",
       "6937  1673     42.46  30.78      85.61  76.57  15.35   17.27  87.99     57.14   \n",
       "6938  1433     25.87  55.54      30.88  95.40  11.65   15.00  88.35     55.97   \n",
       "6939  1495     39.29  16.94      85.79  69.88  93.44   13.71  91.04     58.60   \n",
       "\n",
       "      pronoun  ...  Comma  Colon  SemiC  QMark  Exclam  Dash  Quote  Apostro   \n",
       "0       14.66  ...   2.60   0.37   0.19   1.48    0.00  1.95    0.0     3.62  \\\n",
       "1       20.84  ...   2.38   0.34   0.00   1.70    0.23  0.91    0.0     6.12   \n",
       "2       17.01  ...   2.51   0.06   0.00   0.13    0.06  1.00    0.0     2.20   \n",
       "3       19.59  ...   4.43   2.27   0.00   0.82    1.44  0.10    0.0     4.43   \n",
       "4       17.48  ...   4.48   5.30   0.07   1.42    1.49  1.79    0.0     1.57   \n",
       "...       ...  ...    ...    ...    ...    ...     ...   ...    ...      ...   \n",
       "6935    17.96  ...   3.91   0.96   0.00   0.55    0.34  1.64    0.0     2.40   \n",
       "6936    20.19  ...   3.87   0.24   0.00   0.18    0.12  0.42    0.0     6.41   \n",
       "6937    19.13  ...   3.95   0.24   0.06   0.24    1.49  0.30    0.0     2.39   \n",
       "6938    17.10  ...   1.33   0.21   0.07   1.05    2.58  0.70    0.0     2.37   \n",
       "6939    16.66  ...   7.02   0.80   0.00   0.13    0.07  0.74    0.0     1.54   \n",
       "\n",
       "      Parenth  OtherP  \n",
       "0        1.67   19.20  \n",
       "1        0.45   19.71  \n",
       "2        0.00   10.48  \n",
       "3        0.41   11.44  \n",
       "4        0.97   12.99  \n",
       "...       ...     ...  \n",
       "6935     2.26   11.79  \n",
       "6936     0.12    9.67  \n",
       "6937     0.66    9.38  \n",
       "6938     0.98   11.30  \n",
       "6939     0.74   10.57  \n",
       "\n",
       "[6940 rows x 93 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cafadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming df is your DataFrame and it includes an 'MBTI' column\n",
    "# Also assuming all your LIWC results are numerical. If not, you might need to convert them first.\n",
    "\n",
    "# Convert target variable into numerical form\n",
    "le = LabelEncoder()\n",
    "df['MBTI'] = le.fit_transform(df['MBTI'])\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.drop('MBTI', axis=1)\n",
    "y = df['MBTI']\n",
    "\n",
    "# Create new entityset to hold our data\n",
    "es = ft.EntitySet(id='mbti_data')\n",
    "\n",
    "# Add the entire data frame as an entity\n",
    "es = es.add_dataframe(dataframe_name='data', dataframe=X, \n",
    "                      index='index')\n",
    "\n",
    "# Run deep feature synthesis\n",
    "features, feature_defs = ft.dfs(entityset=es, target_dataframe_name='data', \n",
    "                                agg_primitives=['mean', 'max', 'min', 'std', 'skew'],\n",
    "                                trans_primitives=['add_numeric', 'multiply_numeric'])\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize TPOT\n",
    "tpot = TPOTClassifier(verbosity=2, max_time_mins=10, population_size=40)\n",
    "\n",
    "# Fit TPOT on training data\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance on test data\n",
    "print(tpot.score(X_test, y_test))\n",
    "\n",
    "# Export the final model\n",
    "tpot.export('tpot_mbti_pipeline.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16fb7d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/yt38/lib/python3.8/site-packages/featuretools/entityset/entityset.py:1910: UserWarning: index index not found in dataframe, creating new integer column\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/yt38/lib/python3.8/site-packages/featuretools/synthesis/deep_feature_synthesis.py:169: UserWarning: Only one dataframe in entityset, changing max_depth to 1 since deeper features cannot be created\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/yt38/lib/python3.8/site-packages/featuretools/synthesis/dfs.py:321: UnusedPrimitiveWarning: Some specified primitives were not used during DFS:\n",
      "  agg_primitives: ['max', 'mean', 'min', 'skew', 'std']\n",
      "This may be caused by a using a value of max_depth that is too small, not setting interesting values, or it may indicate no compatible columns for the primitive were found in the data. If the DFS call contained multiple instances of a primitive in the list above, none of them were used.\n",
      "  warnings.warn(warning_msg, UnusedPrimitiveWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = train_df\n",
    "y = raw_df[\"label\"]\n",
    "\n",
    "es = ft.EntitySet(id='mbti_data')\n",
    "\n",
    "# Add the entire data frame as an entity\n",
    "es = es.add_dataframe(\n",
    "    dataframe_name='data',\n",
    "    dataframe=X, \n",
    "    index='index'\n",
    ")\n",
    "\n",
    "# Run deep feature synthesis\n",
    "features, feature_defs = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name='data', \n",
    "    agg_primitives=['mean', 'max', 'min', 'std', 'skew'],\n",
    "    trans_primitives=['add_numeric', 'multiply_numeric']\n",
    ")\n",
    "\n",
    "# Split t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt38",
   "language": "python",
   "name": "yt38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
